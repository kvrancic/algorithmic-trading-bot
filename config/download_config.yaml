# Historical Data Download Configuration
# Example configuration file for download_historical_data.py

# Symbols to download (can be overridden via command line)
symbols:
  - "AAPL"    # Apple Inc.
  - "TSLA"    # Tesla Inc.
  - "GOOGL"   # Alphabet Inc.
  - "MSFT"    # Microsoft Corp.
  - "AMZN"    # Amazon.com Inc.
  - "NVDA"    # NVIDIA Corp.
  - "BTC-USD" # Bitcoin
  - "ETH-USD" # Ethereum
  - "SPY"     # S&P 500 ETF
  - "QQQ"     # NASDAQ ETF
  
  #- "META"    # Meta Platforms Inc.
  #- "NFLX"    # Netflix Inc.
  #- "AMD"     # Advanced Micro Devices
  #- "INTC"    # Intel Corp.
  #- "BABA"    # Alibaba Group
  #- "ORCL"    # Oracle Corp.
  #- "CRM"     # Salesforce Inc.
  #- "PYPL"    # PayPal Holdings
  #- "ADBE"    # Adobe Inc.
  #- "CSCO"    # Cisco Systems
  #- "PEP"     # PepsiCo Inc.
  #- "KO"      # Coca-Cola Co.
  #- "DIS"     # Walt Disney Co.
  #- "V"       # Visa Inc.
  #- "MA"      # Mastercard Inc.
  #- "JPM"     # JPMorgan Chase & Co.
  #- "BAC"     # Bank of America
  #- "WMT"     # Walmart Inc.
  #- "HD"      # Home Depot
  #- "COST"    # Costco Wholesale
  #- "MCD"     # McDonald's Corp.
  #- "SBUX"    # Starbucks Corp.
  #- "T"       # AT&T Inc.
  #- "VZ"      # Verizon Communications
  #- "UNH"     # UnitedHealth Group
  #- "PFE"     # Pfizer Inc.
  #- "MRK"     # Merck & Co.
  #- "ABBV"    # AbbVie Inc.
  #- "CVX"     # Chevron Corp.
  #- "XOM"     # Exxon Mobil Corp.
  #- "BA"      # Boeing Co.
  #- "GE"      # General Electric
  #- "CAT"     # Caterpillar Inc.
  #- "GM"      # General Motors
  #- "F"       # Ford Motor Co.
  #- "HON"     # Honeywell International
  #- "MMM"     # 3M Company
  #- "NKE"     # Nike Inc.
  #- "LMT"     # Lockheed Martin
  #- "GS"      # Goldman Sachs
  #- "MS"      # Morgan Stanley
  #- "BLK"     # BlackRock Inc.
  #- "SCHW"    # Charles Schwab
  #- "TMO"     # Thermo Fisher Scientific
  #- "ABT"     # Abbott Laboratories
  #- "MDT"     # Medtronic plc
  #- "ISRG"    # Intuitive Surgical
  #- "NOW"     # ServiceNow Inc.
  #- "SNOW"    # Snowflake Inc.
  #- "PLTR"    # Palantir Technologies
  #- "UBER"    # Uber Technologies
  #- "LYFT"    # Lyft Inc.
  #- "SHOP"    # Shopify Inc.
  #- "SQ"      # Block Inc. (Square)
  #- "ROKU"    # Roku Inc.
  #- "ZM"      # Zoom Video Communications
  #- "DOCU"    # DocuSign Inc.
  #- "TWLO"    # Twilio Inc.
  #- "DDOG"    # Datadog Inc.
  #- "CRWD"    # CrowdStrike Holdings
  #- "OKTA"    # Okta Inc.
  #- "ZS"      # Zscaler Inc.
  #- "NET"     # Cloudflare Inc.
  #- "TEAM"    # Atlassian Corp.
  #- "ASML"    # ASML Holding
  #- "SAP"     # SAP SE
  #- "SONY"    # Sony Group Corp.
  #- "TM"      # Toyota Motor Corp.
  #- "HMC"     # Honda Motor Co.
  #- "NSANY"   # Nissan Motor Co.
  #- "VWAGY"   # Volkswagen AG
  #- "DDAIF"   # Mercedes-Benz Group
  #- "RACE"    # Ferrari NV
  #- "TSM"     # Taiwan Semiconductor
  #- "BIDU"    # Baidu Inc.
  #- "JD"      # JD.com Inc.
  #- "NTES"    # NetEase Inc.
  #- "PDD"     # Pinduoduo Inc.
  #- "QCOM"    # Qualcomm Inc.
  #- "AVGO"    # Broadcom Inc.
  #- "TXN"     # Texas Instruments
  #- "MU"      # Micron Technology
  #- "WDAY"    # Workday Inc.
  #- "CLX"     # Clorox Co.
  #- "PG"      # Procter & Gamble
  #- "JNJ"     # Johnson & Johnson
  #- "GILD"    # Gilead Sciences
  #- "AMGN"    # Amgen Inc.
  #- "REGN"    # Regeneron Pharmaceuticals
  #- "VRTX"    # Vertex Pharmaceuticals
  #- "SNY"     # Sanofi
  #- "AZN"     # AstraZeneca
  #- "BP"      # BP plc
  #- "TOT"     # TotalEnergies SE
  #- "ENB"     # Enbridge Inc.
  #- "SU"      # Suncor Energy
  #- "RIO"     # Rio Tinto Group
  #- "BHP"     # BHP Group
  #- "FCX"     # Freeport-McMoRan
  #- "GLD"     # SPDR Gold Trust
  #- "SLV"     # iShares Silver Trust
  #- "ARKK"    # ARK Innovation ETF
  #- "IWM"     # Russell 2000 ETF
  #- "DIA"     # Dow Jones ETF
  #- "EEM"     # Emerging Markets ETF
  #- "VTI"     # Vanguard Total Stock Market ETF

# Number of days of historical data to download
days: 365

# Market data timeframes to download
timeframes:
  - "1min"    # 1-minute bars
  - "5min"    # 5-minute bars
  - "15min"   # 15-minute bars
  - "1hour"   # 1-hour bars
  - "1day"    # Daily bars

# Data types to download
download_market_data: true      # OHLCV market data
download_sentiment_data: true   # Reddit, Twitter, News sentiment
download_fundamental_data: true # Company fundamentals, ratios

# Processing options
generate_features: true    # Generate ML features
validate_data: true       # Validate data quality
clean_data: true         # Clean and normalize data
save_raw_data: true      # Save raw data before processing

# Performance settings
concurrent_downloads: 4   # Number of concurrent symbol downloads
batch_size: 1000         # Records per batch for database insertion

# Database configuration
database:
  url: "sqlite:///data/quantum_sentiment.db"
  echo: false            # SQL query logging
  pool_size: 10
  max_overflow: 20

# Data validation settings
validation:
  strict_mode: false           # Treat warnings as errors
  allow_gaps: true            # Allow gaps in time series
  max_gap_hours: 24.0         # Maximum gap in hours
  allow_missing_volume: true  # Allow missing volume data
  min_price_value: 0.001      # Minimum valid price
  max_price_value: 1000000    # Maximum valid price
  max_price_change_pct: 50.0  # Max single-period price change %
  
  # Sentiment validation
  sentiment_score_range: [-1.0, 1.0]
  confidence_range: [0.0, 1.0]
  max_mention_count: 1000000
  
  # Feature validation
  max_feature_value: 1000000
  min_feature_value: -1000000
  max_missing_ratio: 0.3      # 30% max missing features
  outlier_z_threshold: 5.0

# Data cleaning settings
cleaning:
  # Missing value handling
  handle_missing_values: true
  missing_value_strategy: "interpolate"  # interpolate, forward_fill, backward_fill, drop, median
  max_consecutive_missing: 5
  
  # Outlier handling
  handle_outliers: true
  outlier_method: "clip"          # clip, remove, cap, winsorize
  outlier_threshold: 5.0          # Z-score threshold
  winsorize_limits: [0.01, 0.01]  # 1% on each side
  
  # Price data specific
  fix_ohlc_relationships: true
  remove_zero_volume: false
  min_price_threshold: 0.001
  
  # Feature cleaning
  feature_scaling: false
  scaling_method: "robust"        # standard, robust, minmax
  clip_extreme_features: true
  extreme_feature_threshold: 1000000
  
  # Time series cleaning
  fill_time_gaps: true
  max_gap_fill_hours: 24.0
  interpolation_method: "linear"  # linear, spline, polynomial
  
  # General settings
  remove_duplicates: true
  sort_by_timestamp: true
  validate_after_cleaning: true

# Feature generation settings
features:
  feature_version: "1.0.0"
  parallel_processing: true
  max_workers: 4
  enable_caching: false    # Disable for bulk downloads
  
  # Technical features
  enable_technical: true
  technical_config:
    lookback_periods: [5, 10, 20, 50, 200]
    include_advanced: true
  
  # Sentiment features
  enable_sentiment: true
  sentiment_config:
    sentiment_windows: [1, 4, 12, 24, 48]  # Hours
    decay_factor: 0.95
    confidence_threshold: 0.1
    volume_weight: true
    source_weights:
      reddit: 0.4
      twitter: 0.2
      news: 0.25
      unusual_whales: 0.15
  
  # Fundamental features (placeholder)
  enable_fundamental: true
  fundamental_config: {}
  
  # Market structure features (placeholder)
  enable_market_structure: true
  market_structure_config: {}
  
  # Macro features (placeholder)
  enable_macro: true
  macro_config: {}
  
  # Validation settings
  enable_validation: true
  max_missing_ratio: 0.3
  outlier_threshold: 5.0
  
  # Feature selection
  min_correlation_threshold: 0.01
  max_features: null  # No limit

# Logging configuration
logging:
  level: "INFO"          # DEBUG, INFO, WARNING, ERROR
  format: "json"         # json, console
  log_file: "logs/download.log"
  max_file_size: "100MB"
  backup_count: 5

# API rate limiting
rate_limits:
  alpaca_requests_per_minute: 200
  reddit_requests_per_minute: 60
  twitter_requests_per_minute: 300
  alpha_vantage_requests_per_minute: 5
  
# Retry settings
retry:
  max_attempts: 3
  backoff_factor: 2
  max_backoff: 300  # seconds

# Output settings
output:
  save_reports: true
  report_format: "yaml"  # yaml, json
  compress_data: false
  export_csv: false      # Export cleaned data to CSV