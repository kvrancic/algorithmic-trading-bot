# Historical Data Download Configuration
# Example configuration file for download_historical_data.py

# Symbols to download (can be overridden via command line)
symbols:
  - "AAPL"    # Apple Inc.
  - "TSLA"    # Tesla Inc.
  - "GOOGL"   # Alphabet Inc.
  - "MSFT"    # Microsoft Corp.
  - "AMZN"    # Amazon.com Inc.
  - "NVDA"    # NVIDIA Corp.
  - "BTC-USD" # Bitcoin
  - "ETH-USD" # Ethereum
  - "SPY"     # S&P 500 ETF
  - "QQQ"     # NASDAQ ETF

# Number of days of historical data to download
days: 365

# Market data timeframes to download
timeframes:
  - "1min"    # 1-minute bars
  - "5min"    # 5-minute bars
  - "15min"   # 15-minute bars
  - "1hour"   # 1-hour bars
  - "1day"    # Daily bars

# Data types to download
download_market_data: true      # OHLCV market data
download_sentiment_data: true   # Reddit, Twitter, News sentiment
download_fundamental_data: true # Company fundamentals, ratios

# Processing options
generate_features: true    # Generate ML features
validate_data: true       # Validate data quality
clean_data: true         # Clean and normalize data
save_raw_data: true      # Save raw data before processing

# Performance settings
concurrent_downloads: 4   # Number of concurrent symbol downloads
batch_size: 1000         # Records per batch for database insertion

# Database configuration
database:
  url: "sqlite:///data/quantum_sentiment.db"
  echo: false            # SQL query logging
  pool_size: 10
  max_overflow: 20

# Data validation settings
validation:
  strict_mode: false           # Treat warnings as errors
  allow_gaps: true            # Allow gaps in time series
  max_gap_hours: 24.0         # Maximum gap in hours
  allow_missing_volume: true  # Allow missing volume data
  min_price_value: 0.001      # Minimum valid price
  max_price_value: 1000000    # Maximum valid price
  max_price_change_pct: 50.0  # Max single-period price change %
  
  # Sentiment validation
  sentiment_score_range: [-1.0, 1.0]
  confidence_range: [0.0, 1.0]
  max_mention_count: 1000000
  
  # Feature validation
  max_feature_value: 1000000
  min_feature_value: -1000000
  max_missing_ratio: 0.3      # 30% max missing features
  outlier_z_threshold: 5.0

# Data cleaning settings
cleaning:
  # Missing value handling
  handle_missing_values: true
  missing_value_strategy: "interpolate"  # interpolate, forward_fill, backward_fill, drop, median
  max_consecutive_missing: 5
  
  # Outlier handling
  handle_outliers: true
  outlier_method: "clip"          # clip, remove, cap, winsorize
  outlier_threshold: 5.0          # Z-score threshold
  winsorize_limits: [0.01, 0.01]  # 1% on each side
  
  # Price data specific
  fix_ohlc_relationships: true
  remove_zero_volume: false
  min_price_threshold: 0.001
  
  # Feature cleaning
  feature_scaling: false
  scaling_method: "robust"        # standard, robust, minmax
  clip_extreme_features: true
  extreme_feature_threshold: 1000000
  
  # Time series cleaning
  fill_time_gaps: true
  max_gap_fill_hours: 24.0
  interpolation_method: "linear"  # linear, spline, polynomial
  
  # General settings
  remove_duplicates: true
  sort_by_timestamp: true
  validate_after_cleaning: true

# Feature generation settings
features:
  feature_version: "1.0.0"
  parallel_processing: true
  max_workers: 4
  enable_caching: false    # Disable for bulk downloads
  
  # Technical features
  enable_technical: true
  technical_config:
    lookback_periods: [5, 10, 20, 50, 200]
    include_advanced: true
  
  # Sentiment features
  enable_sentiment: true
  sentiment_config:
    sentiment_windows: [1, 4, 12, 24, 48]  # Hours
    decay_factor: 0.95
    confidence_threshold: 0.1
    volume_weight: true
    source_weights:
      reddit: 0.4
      twitter: 0.2
      news: 0.25
      unusual_whales: 0.15
  
  # Fundamental features (placeholder)
  enable_fundamental: true
  fundamental_config: {}
  
  # Market structure features (placeholder)
  enable_market_structure: true
  market_structure_config: {}
  
  # Macro features (placeholder)
  enable_macro: true
  macro_config: {}
  
  # Validation settings
  enable_validation: true
  max_missing_ratio: 0.3
  outlier_threshold: 5.0
  
  # Feature selection
  min_correlation_threshold: 0.01
  max_features: null  # No limit

# Logging configuration
logging:
  level: "INFO"          # DEBUG, INFO, WARNING, ERROR
  format: "json"         # json, console
  log_file: "logs/download.log"
  max_file_size: "100MB"
  backup_count: 5

# API rate limiting
rate_limits:
  alpaca_requests_per_minute: 200
  reddit_requests_per_minute: 60
  twitter_requests_per_minute: 300
  alpha_vantage_requests_per_minute: 5
  
# Retry settings
retry:
  max_attempts: 3
  backoff_factor: 2
  max_backoff: 300  # seconds

# Output settings
output:
  save_reports: true
  report_format: "yaml"  # yaml, json
  compress_data: false
  export_csv: false      # Export cleaned data to CSV